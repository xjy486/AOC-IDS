{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch.nn.functional as F\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix, precision_score, recall_score, f1_score\n",
    "import scipy.optimize as opt\n",
    "import torch.distributions as dist\n",
    "from sklearn.metrics import accuracy_score\n",
    "import argparse\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "超参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数\n",
    "tem = 0.02\n",
    "bs = 128\n",
    "seed = 5009\n",
    "seed_round = 5\n",
    "epochs = 800\n",
    "epoch_online=1\n",
    "sample_interval = 2784\n",
    "flip_percent = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    train_data=pd.read_csv('en_UNSW_NB15_train.csv')\n",
    "    test_data=pd.read_csv('en_UNSW_NB15_test.csv')\n",
    "    y_train=train_data['label']\n",
    "    y_test=test_data['label']\n",
    "    X_train=train_data.drop(columns=['label'])\n",
    "    X_test=test_data.drop(columns=['label'])\n",
    "    normalize=MinMaxScaler()\n",
    "    X_train=normalize.fit_transform(X_train)\n",
    "    X_test=normalize.fit_transform(X_test)\n",
    "    return X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_test,y_test=get_dataset()\n",
    "# 转换为torch张量\n",
    "x_train,y_train=torch.FloatTensor(x_train).to(device),torch.LongTensor(y_train).to(device)\n",
    "x_test,y_test=torch.FloatTensor(x_test).to(device),torch.LongTensor(y_test).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y,y_pred):\n",
    "    y= y.cpu().detach().numpy()\n",
    "    y_pred= y_pred.cpu().detach().numpy()\n",
    "    # 混淆矩阵\n",
    "    print(\"Confusion matrix\")\n",
    "    print(confusion_matrix(y, y_pred))\n",
    "    # Accuracy \n",
    "    print('Accuracy ',accuracy_score(y, y_pred))\n",
    "    # Precision \n",
    "    print('Precision ',precision_score(y, y_pred))\n",
    "    # Recall\n",
    "    print('Recall ',recall_score(y, y_pred))\n",
    "    # F1 score\n",
    "    print('F1 score ',f1_score(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_loss(losses,epoch):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title(f\"{epoch} Training Loss\")\n",
    "    plt.plot(losses, marker='o')\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AE自编码器模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(AE, self).__init__()\n",
    "        # 计算输入维度的最近的2的幂次方，比如输入维度是206，则最近的2的幂次方是128\n",
    "        nearest_power_of_2 = 2 ** round(math.log2(input_dim))\n",
    "        \n",
    "        second_fourth_layer_size = nearest_power_of_2 // 2\n",
    "        third_layer_size = nearest_power_of_2 // 4\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, second_fourth_layer_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(second_fourth_layer_size, third_layer_size)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(third_layer_size, second_fourth_layer_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(second_fourth_layer_size, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CRC对比损失模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRCLoss(nn.Module):\n",
    "    def __init__(self, device, temperature=0.1, scale_by_temperature=True):\n",
    "        super(CRCLoss, self).__init__()\n",
    "        self.device = device\n",
    "        self.temperature = temperature\n",
    "        self.scale_by_temperature = scale_by_temperature\n",
    "\n",
    "    def forward(self, features, labels=None, recon_features=None):\n",
    "        # 计算特征的归一化表示\n",
    "        features = F.normalize(features, p=2, dim=1)\n",
    "        batch_size = features.shape[0]\n",
    "        num_norm = len(labels==0)\n",
    "        ## contiguous方法确保张量在内存是连续存储的，因为变换视图操作需要确保张量在内存中是连续存储的\n",
    "        labels = labels.contiguous().view(-1, 1) # batch_size * 1\n",
    "        \n",
    "        if labels.shape[0] != batch_size:\n",
    "            raise ValueError('Batch size of features and labels do not match.')\n",
    "        \n",
    "        # 计算余弦相似度，cosine_sim[i][j]表示features[i]和features[j]的余弦相似度，矩阵大小为batch_size * batch_size\n",
    "        cosine_sim = torch.nn.functional.cosine_similarity(features.unsqueeze(1), features.unsqueeze(0), dim = -1)/self.temperature\n",
    "        # 将余弦相似度的对角线元素设置为0\n",
    "        mask_diag = torch.eye(batch_size, dtype=torch.bool)\n",
    "        cosine_sim[mask_diag] = 0\n",
    "        # 正样本对\n",
    "        sim_pos = cosine_sim[(labels==0).squeeze()]\n",
    "        # 正样本对间的余弦相似度\n",
    "        sim_pos_pos = sim_pos[:,(labels==0).squeeze()] \n",
    "        # 正样本与负样本间的余弦相似度\n",
    "        sim_pos_neg = sim_pos[:,(labels==1).squeeze()]\n",
    "        # 计算正样本与负样本间的分数和\n",
    "        # sum_pos_neg = torch.sum(torch.exp(sim_pos_neg), axis=1, keepdims=True)\n",
    "        sum_pos_neg = torch.sum(torch.exp(sim_pos_neg))\n",
    "        # 计算分母\n",
    "        denominator = torch.exp(sim_pos_pos) + sum_pos_neg       \n",
    "        loss = -(sim_pos_pos-torch.log(denominator))  \n",
    "        \n",
    "        \n",
    "        if self.scale_by_temperature:\n",
    "            loss = loss * self.temperature\n",
    "        # 计算损失\n",
    "        loss= loss.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADM自主决策"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_pdf(x, mean, std):\n",
    "    pdf = 1/(std*np.sqrt(2*np.pi))*np.exp(-(x-mean)**2/(2*std**2))\n",
    "    return pdf\n",
    "def log_likelihood(params,data):\n",
    "    data = data.cpu().detach().numpy()\n",
    "    mean_pos_enc, std_pos_enc, mean_neg_enc, std_neg_enc = params\n",
    "    pdf1 = gaussian_pdf(data, mean_pos_enc, std_pos_enc)\n",
    "    pdf2 = gaussian_pdf(data, mean_neg_enc, std_neg_enc)\n",
    "    mixture_pdf = 0.5*pdf1 + 0.5*pdf2\n",
    "    log_likelihood = -np.sum(np.log(mixture_pdf))\n",
    "    \n",
    "    return log_likelihood\n",
    "def predict(norm_enc, norm_dec, x_train, y_train, x_test, model):\n",
    "    x_train_pos=x_train[(y_train==0).squeeze()]\n",
    "    x_train_neg=x_train[(y_train==1).squeeze()]\n",
    "    \n",
    "    # 训练集全体样本编码和解码特征\n",
    "    train_enc = F.normalize(model(x_train)[0], p=2, dim=1)\n",
    "    train_dec = F.normalize(model(x_train)[1], p=2, dim=1)\n",
    "    # 训练集正样本编码和解码特征\n",
    "    train_enc_pos = F.normalize(model(x_train_pos)[0], p=2, dim=1)\n",
    "    train_dec_pos = F.normalize(model(x_train_pos)[1], p=2, dim=1)\n",
    "    # 训练集负样本编码和解码特征\n",
    "    train_enc_neg = F.normalize(model(x_train_neg)[0], p=2, dim=1)\n",
    "    train_dec_neg = F.normalize(model(x_train_neg)[1], p=2, dim=1)\n",
    "    \n",
    "    # 分别计算训练集正样本特征和平均正样本特征的余弦相似度 负样本同理 全体样本同理 \n",
    "    sim_pos_norm_enc = F.cosine_similarity(train_enc_pos, norm_enc.unsqueeze(0), dim=1) \n",
    "    sim_pos_norm_dec = F.cosine_similarity(train_dec_pos, norm_dec.unsqueeze(0), dim=1)\n",
    "    sim_neg_norm_enc = F.cosine_similarity(train_enc_neg, norm_enc.unsqueeze(0), dim=1)\n",
    "    sim_neg_norm_dec = F.cosine_similarity(train_dec_neg, norm_dec.unsqueeze(0), dim=1)\n",
    "    sim_all_norm_enc = F.cosine_similarity(train_enc, norm_enc.unsqueeze(0), dim=1)\n",
    "    sim_all_norm_dec = F.cosine_similarity(train_dec, norm_dec.unsqueeze(0), dim=1)\n",
    "    # 进行排序\n",
    "    sort_sim_pos_norm_enc, indices = torch.sort(sim_pos_norm_enc)\n",
    "    sort_sim_pos_norm_dec, indices = torch.sort(sim_pos_norm_dec)\n",
    "    sort_sim_neg_norm_enc, indices = torch.sort(sim_neg_norm_enc)\n",
    "    sort_sim_neg_norm_dec, indices = torch.sort(sim_neg_norm_dec)\n",
    "\n",
    "    \n",
    "    ## 初始化参数\n",
    "    mean_pos_enc = torch.mean(sort_sim_pos_norm_enc).cpu().detach().numpy()\n",
    "    std_pos_enc = torch.std(sort_sim_pos_norm_enc).cpu().detach().numpy()\n",
    "    mean_pos_dec = torch.mean(sort_sim_pos_norm_dec).cpu().detach().numpy()\n",
    "    std_pos_dec = torch.std(sort_sim_pos_norm_dec).cpu().detach().numpy()\n",
    "    mean_neg_enc = torch.mean(sort_sim_neg_norm_enc).cpu().detach().numpy()\n",
    "    std_neg_enc = torch.std(sort_sim_neg_norm_enc).cpu().detach().numpy()\n",
    "    mean_neg_dec = torch.mean(sort_sim_neg_norm_dec).cpu().detach().numpy()\n",
    "    std_neg_dec = torch.std(sort_sim_neg_norm_dec).cpu().detach().numpy()\n",
    "    initial_params_enc = [mean_pos_enc, std_pos_enc, mean_neg_enc, std_neg_enc]\n",
    "    initial_params_dec = [mean_pos_dec, std_pos_dec, mean_neg_dec, std_neg_dec]\n",
    "    # 拟合高斯分布\n",
    "    fit_enc = opt.minimize(log_likelihood, initial_params_enc, args=(sim_all_norm_enc,), method='Nelder-Mead')\n",
    "    fit_dec = opt.minimize(log_likelihood, initial_params_dec, args=(sim_all_norm_dec,), method='Nelder-Mead') \n",
    "    # print(\"enc init\")\n",
    "    # print(initial_params_enc)\n",
    "    # print(\"dec init\")\n",
    "    # print(initial_params_dec)\n",
    "    mean1_enc, std1_enc, mean2_enc, std2_enc = fit_enc.x\n",
    "    mean1_dec, std1_dec, mean2_dec, std2_dec = fit_dec.x\n",
    "    # print(\"encoder:\")\n",
    "    # print(mean1_enc, std1_enc, mean2_enc, std2_enc)\n",
    "    # print(\"decoder:\")\n",
    "    # print(mean1_dec, std1_dec, mean2_dec, std2_dec)\n",
    "    # 选择均值小的作为正常样本的均值\n",
    "    if mean1_enc < mean2_enc:\n",
    "        mean_pos_enc, mean_neg_enc = mean1_enc, mean2_enc\n",
    "        std_pos_enc, std_neg_enc = std1_enc, std2_enc\n",
    "        gaussian_pos_enc = dist.Normal(mean_pos_enc, std_pos_enc)\n",
    "        gaussian_neg_enc = dist.Normal(mean_neg_enc, std_neg_enc)\n",
    "    else:\n",
    "        mean_pos_enc, mean_neg_enc = mean2_enc, mean1_enc\n",
    "        std_pos_enc, std_neg_enc = std2_enc, std1_enc\n",
    "        gaussian_pos_enc = dist.Normal(mean_pos_enc, std_pos_enc)\n",
    "        gaussian_neg_enc = dist.Normal(mean_neg_enc, std_neg_enc)\n",
    "    if mean1_dec < mean2_dec:\n",
    "        mean_pos_dec, mean_neg_dec = mean1_dec, mean2_dec\n",
    "        std_pos_dec, std_neg_dec = std1_dec, std2_dec\n",
    "        gaussian_pos_dec = dist.Normal(mean_pos_dec, std_pos_dec)\n",
    "        gaussian_neg_dec = dist.Normal(mean_neg_dec, std_neg_dec)\n",
    "    else:\n",
    "        mean_pos_dec, mean_neg_dec = mean2_dec, mean1_dec\n",
    "        std_pos_dec, std_neg_dec = std2_dec, std1_dec\n",
    "        gaussian_pos_dec = dist.Normal(mean_pos_dec, std_pos_dec)\n",
    "        gaussian_neg_dec = dist.Normal(mean_neg_dec, std_neg_dec)\n",
    "    # gaussian_pos_enc = dist.Normal(mean1_enc, std1_enc)\n",
    "    # gaussian_neg_enc = dist.Normal(mean2_enc, std2_enc)\n",
    "    # gaussian_pos_dec = dist.Normal(mean1_dec, std1_dec)\n",
    "    # gaussian_neg_dec = dist.Normal(mean2_dec, std2_dec)\n",
    "    \n",
    "    # 计算测试数据与正常样本的余弦相似度\n",
    "    test_enc = F.cosine_similarity(F.normalize(model(x_test)[0], p=2, dim=1), norm_enc.unsqueeze(0), dim=1)\n",
    "    test_dec = F.cosine_similarity(F.normalize(model(x_test)[1], p=2, dim=1), norm_dec.unsqueeze(0), dim=1)\n",
    "    # 使用解码器和编码器分别预测\n",
    "    y_pred_enc = torch.where(gaussian_pos_enc.log_prob(test_enc) > gaussian_neg_enc.log_prob(test_enc), 1, 0)\n",
    "    y_pred_dec = torch.where(gaussian_pos_dec.log_prob(test_dec) > gaussian_neg_dec.log_prob(test_dec), 1, 0)\n",
    "    # 投票预测\n",
    "    diff_enc = torch.abs(gaussian_pos_enc.log_prob(test_enc)-gaussian_neg_enc.log_prob(test_enc))\n",
    "    diff_dec = torch.abs(gaussian_pos_dec.log_prob(test_dec)-gaussian_neg_dec.log_prob(test_dec))\n",
    "    y_pred = torch.where(diff_enc > diff_dec, y_pred_enc, y_pred_dec)\n",
    "    return y_pred,y_pred_enc,y_pred_dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "离线学习，所以训练集数据都被用于训练  \n",
    "没有在线学习环节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=196, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): ReLU()\n",
       "    (1): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=128, out_features=196, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "# 设置随机种子\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "# 创建张量数据集\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "# 创建一个损失函数\n",
    "criterion = CRCLoss(device, tem)\n",
    "# 输入维度\n",
    "input_dim = x_train.shape[1]\n",
    "# 创建自编码器模型\n",
    "model = AE(input_dim).to(device)\n",
    "# 创建优化器\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# 调整模型进入训练模式\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ac29d631a3439993cb76b984304382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################## 初始化训练模型 ##########################\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    \n",
    "    #  j是批次索引，data是一个元组，包含输入和标签\n",
    "    for _ ,data in enumerate(train_loader,0):\n",
    "        # 获取输入和标签\n",
    "        inputs, labels = data # inputs.shape = (128, 206), labels.shape = (128,)\n",
    "        # 将标签移动到设备上\n",
    "        labels = labels.to(device)\n",
    "        # 优化器梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        # 前向传播\n",
    "        enc_features, dec_features = model(inputs.to(device))     \n",
    "        # 计算损失\n",
    "        loss=criterion(enc_features, labels)+criterion(dec_features, labels)\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        # 更新权重\n",
    "        optimizer.step()\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在线学习阶段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评估模型（在测试集上训练）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[36829   171]\n",
      " [11312 34020]]\n",
      "Accuracy  0.8605281057183112\n",
      "Precision  0.9949986838641748\n",
      "Recall  0.7504632489190859\n",
      "F1 score  0.855601524087371\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "normal_enc = torch.mean(F.normalize(model(x_train[(y_train == 0).squeeze()])[0], p=2, dim=1), dim=0)\n",
    "normal_dec = torch.mean(F.normalize(model(x_train[(y_train == 0).squeeze()])[1], p=2, dim=1), dim=0)\n",
    "x_test = x_test.to(device)\n",
    "y_pred,_,_ = predict(normal_enc, normal_dec, x_train,y_train , x_test , model)\n",
    "evaluate(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_xjy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
